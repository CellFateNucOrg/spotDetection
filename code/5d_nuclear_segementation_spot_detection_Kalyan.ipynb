{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecdc50a0",
   "metadata": {},
   "source": [
    "# Nuclear segmentation with emerin ring and spot detection\n",
    "\n",
    "Scripts to detect nuclei from 5d images (t,c,z,y,x) where channel 0 is green spots and channel 1 is red emerin rings.\n",
    "Mostly based on scripts from Lucien Hinderling, with some modifications and cleanup by Jennifer Semple.\n",
    "\n",
    "Nuclear segmentation carried out with Cellpose.\n",
    "Spot detection carried out with pytrack.\n",
    "\n",
    "**Inputs**:\n",
    "\n",
    "raw_input_path and denoised_input_path for directories containing raw and denoised images and output_path where results will be put. raw_input_path is used to create a dataframe with paths to images and the following \n",
    "columns:\n",
    "\n",
    "*filename\tdate\texperiment\tstrain\tprotein\tid  raw_filepath    denoised_filepath*\n",
    "\n",
    "example line:\n",
    "\n",
    "*20240915_1268_E_bean_15um\t20240915\t3d\t1268\tDPY27\tDPY27_3d_20240915_1268_E_bean_15um\t/mnt/external.data/MeisterLab/Dario/Imaging/DP...\t/mnt/external.data/MeisterLab/Dario/Imaging/DP...*\n",
    "\n",
    "the id column is used to name images in the output_path directories\n",
    "\n",
    "**Outputs**:\n",
    "\n",
    "segmentation masks (.tif files) in output_path/segmentation/\n",
    "\n",
    "distance masks (.tif files) in output_path/edt/\n",
    "\n",
    "nuclear measurements (.csv files) in output_path/nuclei/\n",
    "\n",
    "intensity measurements for nuclei with arrays of intensity/distance from middle slice of each nuclear mask (.pkl files) in as well as other nuclear measurments and data are in output_path/dist/ \n",
    "\n",
    "qc plots of segmentation on original image (segmentation_XXX.pdf), individual masked nuclei (cropped_nuclei_XXX.pdf) in output_path/qc/\n",
    "\n",
    "spot detection (.csv files, doesn't work very well) in output_path/spots/ with some qc in output_path/qc/spots*.pdf and spotGMM*.pdf\n",
    "\n",
    "### Setting you might need to change\n",
    "\n",
    "raw_input_path - should point to directory where the nd2 images are '/mnt/external.data/MeisterLab/Dario/SDC1/1273/20241108_hs'. \n",
    "Scripts assume the denoised images are one level down in N2V_sdc1_dpy27_mSG_emr1_mCh/denoised folder.\n",
    "Scripts assume that the directory above the raw_input drive contains strain name, and the directory above that contains protein name.\n",
    "\n",
    "output_path - create a directory for the analysis. results will be stored in a protein/strain/date structure same as in the raw_input_path.\n",
    "\n",
    "Make sure file paths end with  '/'\n",
    "\n",
    "If you are not working on the server, but rather locally on a mac with izbkingston mounted as an external drive, you need to change 'server = True' to False (currently this only works for mac externally mounted drives).\n",
    "\n",
    "Set the channels for nuclear stain (nucChannel) and for spots (spotChannel) [currently 0 and 1 respectively] \n",
    "\n",
    "maxradius - maximum number of pixel-lag used in autocorrelation. (12 pixels is about 3x PSF in images with pixel diameter of 65nm), but longer lags might be worth investigaing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4864532e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import napari\n",
    "import torch\n",
    "from skimage.measure import regionprops_table, regionprops\n",
    "from skimage.color import label2rgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import trackpy as tp\n",
    "import cellpose\n",
    "from cellpose import models\n",
    "import edt\n",
    "import glob\n",
    "import os\n",
    "import tqdm\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from bioio import BioImage\n",
    "import bioio_nd2\n",
    "import bioio_tifffile\n",
    "from bioio.writers import OmeTiffWriter\n",
    "import scipy.stats as stats\n",
    "from scipy import optimize\n",
    "\n",
    "\n",
    "#anisotropy = (3,1,1) # Relative scale of (Z,X,Y) axes now calculated inside scripts\n",
    "\n",
    "nucChannel = 0 # red emerin rings\n",
    "spotChannel = 0 # green spots\n",
    "#server = True # is the script running on the server or mounted on mac\n",
    "maxradius = 12 # maximum radius for autocorrelation (in pixels). 12 is probably a good value for normal nuclear spots\n",
    "path_type=\"wsl\"\n",
    "\n",
    "# def macMount(path): # tansforms server path to path for izbkingston mounted on mac\n",
    "#     newpath = path.replace('/mnt/','/Volumes/')\n",
    "#     return newpath\n",
    "\n",
    "# in lucien's original scripts:\n",
    "# channel 0 is green spots\n",
    "# channel 1 is red emerin\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338c03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_path(path):\n",
    "    if path_type == \"server\":\n",
    "        return path\n",
    "    if path_type == \"mac\":\n",
    "        newpath = path.replace('/mnt/external.data/','/Volumes/external.data/')\n",
    "        return newpath\n",
    "    if path_type == \"wsl\":\n",
    "        newpath = path.replace('/mnt/external.data/','/mnt/izbkingston/')\n",
    "        return newpath\n",
    "    \n",
    "def correct_save_path(df, col_names=['raw_filepath', 'denoised_filepath']):\n",
    "    if path_type == \"server\":\n",
    "        return df\n",
    "    if path_type == \"mac\":\n",
    "        for col in col_names:\n",
    "            df[col] = df[col].str.replace('/Volumes/external.data/','/mnt/external.data/')\n",
    "        return df\n",
    "    if path_type == \"wsl\":\n",
    "        for col in col_names:\n",
    "            df[col] = df[col].str.replace('/mnt/izbkingston/','/mnt/external.data/')\n",
    "        return df\n",
    "\n",
    "def correct_loaded_path(df, col_names=['raw_filepath', 'denoised_filepath']):\n",
    "    if path_type == \"server\":\n",
    "        return df\n",
    "    if path_type == \"mac\":\n",
    "        for col in col_names:\n",
    "            df[col] = df[col].str.replace('/mnt/external.data/','/Volumes/external.data/')\n",
    "        return df\n",
    "    if path_type == \"wsl\":\n",
    "        for col in col_names:\n",
    "            df[col] = df[col].str.replace('/mnt/external.data/','/mnt/izbkingston/')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d2eb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# on server\n",
    "## raw images input path\n",
    "#raw_input_path = '/mnt/external.data/MeisterLab/Dario/DPY27/1268/20241107_e_hs/'\n",
    "#raw_input_path = '/mnt/external.data/MeisterLab/Dario/SDC1/1273/20241108_e_hs/'\n",
    "#raw_input_path = '/mnt/external.data/MeisterLab/Dario/DPY27/1268/20241010_e_tl/'\n",
    "#raw_input_path = '/mnt/external.data/MeisterLab/Dario/SDC1/1273/20241010_e_tl/'\n",
    "#raw_input_path = '/mnt/external.data/MeisterLab/Dario/SDC1/1273/20240813_3d/'\n",
    "\n",
    "## denoised images input path\n",
    "#denoised_input_path = os.path.join(raw_input_path,'N2V_1268RG_1273RG/denoised/')\n",
    "#denoised_input_path = os.path.join(raw_input_path,'N2V_sdc1_dpy27_mSG_emr1_mCh/denoised/')\n",
    "\n",
    "# raw_file_name_pattern = \"/*.nd2\"\n",
    "# denoised_file_name_pattern = \"/*_n2v.tif\"\n",
    "# raw_filepaths = sorted(glob.glob(raw_input_path + raw_file_name_pattern,recursive=True))\n",
    "# raw_filepaths = [filepath for filepath in raw_filepaths if '_bad.nd2' not in filepath]\n",
    "\n",
    "# print(f\"Found {len(raw_filepaths)} *.nd2 files.\")\n",
    "\n",
    "## base of output path (dataset specific directory will be created automatically)\n",
    "#output_path_base = '/mnt/external.data/MeisterLab/jsemple/lhinder/segmentation_Dario\n",
    "\n",
    "output_path = correct_path('/mnt/external.data/MeisterLab/jsemple/lhinder/segementation_Kalyan/2025-04-03_bet1-mSG_wPM1353')\n",
    "# if not server:\n",
    "#     output_path = macMount(output_path)\n",
    "\n",
    "df = pd.read_csv(os.path.join(output_path,'fileList_wormMasks.csv'))\n",
    "\n",
    "df = correct_loaded_path(df)\n",
    "\n",
    "# # function to get metadata from dario's file structure\n",
    "# def dario_metadata(raw_input_path, raw_filepaths, output_path_base, denoised_input_path):\n",
    "#     # extract identifying directories from raw_input_path\n",
    "#     protein_strain_date = os.path.normpath(raw_input_path).split(os.sep)[-3:]\n",
    "#     protein_strain_date = '/'.join(protein_strain_date)\n",
    "#     output_path = os.path.join(output_path_base, protein_strain_date)\n",
    "\n",
    "#     df = pd.DataFrame()\n",
    "#     df['filename'] = [os.path.basename(filepath)[:-4] for filepath in raw_filepaths]\n",
    "#     tmpdate = [os.path.normpath(filepath).split(os.sep)[-2] for filepath in raw_filepaths]\n",
    "#     df['date'] = pd.Series([exp.split('_')[0] for exp in tmpdate])\n",
    "#     df['stage'] = pd.Series([exp.split('_')[1] for exp in tmpdate])\n",
    "#     df['experiment'] = pd.Series([exp.split('_')[2] for exp in tmpdate])\n",
    "#     df['strain'] = [os.path.normpath(filepath).split(os.sep)[-3] for filepath in raw_filepaths]\n",
    "#     df['protein'] = [os.path.normpath(filepath).split(os.sep)[-4] for filepath in raw_filepaths]\n",
    "#     df['id'] = df['protein'] + '_' + df['stage'] + '_' + df['experiment'] + '_' + df['filename'] \n",
    "#     df['raw_filepath'] = raw_filepaths\n",
    "#     df['denoised_filepath'] = [os.path.join(denoised_input_path,filename+'_n2v.tif') for filename in df['filename']]\n",
    "#     if(server):\n",
    "#         df.to_csv(os.path.join(output_path,'fileList.csv'),index=False)\n",
    "#     return(df, output_path)\n",
    "\n",
    "# df, output_path = dario_metadata(raw_input_path, raw_filepaths, output_path_base, denoised_input_path)\n",
    "\n",
    "# if(not server):\n",
    "#     df=pd.read_csv(os.path.join(output_path,'fileList.csv'))\n",
    "#     for i in range(len(df)):\n",
    "#         df.at[i,'raw_filepath'] = macMount(df.at[i,'raw_filepath'])\n",
    "#         df.at[i,'denoised_filepath'] = macMount(df.at[i,'denoised_filepath'])\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(output_path,\"qc\")):\n",
    "    os.makedirs(os.path.join(output_path,\"qc\"))\n",
    "\n",
    "if not os.path.exists(os.path.join(output_path,\"segmentation\")):\n",
    "    os.makedirs(os.path.join(output_path,\"segmentation\"))\n",
    "\n",
    "if not os.path.exists(os.path.join(output_path,\"edt\")):\n",
    "    os.makedirs(os.path.join(output_path,\"edt\"))\n",
    "\n",
    "if not os.path.exists(os.path.join(output_path,\"edt\")):\n",
    "    os.makedirs(os.path.join(output_path,\"edt\"))\n",
    "\n",
    "if not os.path.exists(os.path.join(output_path,\"nuclei\")):\n",
    "    os.makedirs(os.path.join(output_path,\"nuclei\"))\n",
    "\n",
    "if not os.path.exists(os.path.join(output_path,\"dist\")):\n",
    "    os.makedirs(os.path.join(output_path,\"dist\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87afd6",
   "metadata": {},
   "source": [
    "Generate data frame of file paths with metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27817eeb",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "667d650d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only CPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsemple/miniforge3/envs/lhcellpose/lib/python3.10/site-packages/cellpose/resnet_torch.py:280: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(filename, map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.device(0)\n",
    "model_path=correct_path('/mnt/external.data/MeisterLab/lhinder/segmentation_3d_anja/code/worms_1000epochs_v0')\n",
    "#if(not server):\n",
    "#    model_path = macMount(model_path)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    model = models.CellposeModel(pretrained_model=model_path, gpu=True, device =torch.device('cuda:0'))\n",
    "else:\n",
    "    print(\"Only CPU is available\")\n",
    "    model = models.CellposeModel(pretrained_model=model_path, gpu=False)\n",
    "\n",
    "\n",
    "# no gpu, from local machine with izbkingston mounted \n",
    "#model = models.CellposeModel(pretrained_model='/Volumes/external.data/MeisterLab/lhinder/segmentation_3d_anja/code/worms_1000epochs_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a60ef07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "protein",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "strain",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "treatment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "worm_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw_filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "denoised_filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "worm_region",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b525349d-50a8-4328-9f09-3d2feae5e5e8",
       "rows": [
        [
         "0",
         "wPM1353_HS_001",
         "2025-04-03",
         "bet1-mSG",
         "wPM1353",
         "HS",
         "1",
         "bet1-mSG_2025-04-03_wPM1353_HS_001",
         "/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/wPM1353_bet1_mSG/2025_04_03_wPM1353/2025_04_03_wPM1353_HS/wPM1353_HS_001.nd2",
         "/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/wPM1353_bet1_mSG/2025_04_03_wPM1353/2025_04_03_wPM1353_HS/n2v_denoise/denoised/wPM1353_HS_001_green_n2v.tif",
         "tailnuc"
        ],
        [
         "1",
         "wPM1353_HS_002",
         "2025-04-03",
         "bet1-mSG",
         "wPM1353",
         "HS",
         "2",
         "bet1-mSG_2025-04-03_wPM1353_HS_002",
         "/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/wPM1353_bet1_mSG/2025_04_03_wPM1353/2025_04_03_wPM1353_HS/wPM1353_HS_002.nd2",
         "/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/wPM1353_bet1_mSG/2025_04_03_wPM1353/2025_04_03_wPM1353_HS/n2v_denoise/denoised/wPM1353_HS_002_green_n2v.tif",
         "head"
        ],
        [
         "2",
         "wPM1353_HS_003",
         "2025-04-03",
         "bet1-mSG",
         "wPM1353",
         "HS",
         "3",
         "bet1-mSG_2025-04-03_wPM1353_HS_003",
         "/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/wPM1353_bet1_mSG/2025_04_03_wPM1353/2025_04_03_wPM1353_HS/wPM1353_HS_003.nd2",
         "/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/wPM1353_bet1_mSG/2025_04_03_wPM1353/2025_04_03_wPM1353_HS/n2v_denoise/denoised/wPM1353_HS_003_green_n2v.tif",
         "head"
        ],
        [
         "3",
         "wPM1353_HS_004",
         "2025-04-03",
         "bet1-mSG",
         "wPM1353",
         "HS",
         "4",
         "bet1-mSG_2025-04-03_wPM1353_HS_004",
         "/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/wPM1353_bet1_mSG/2025_04_03_wPM1353/2025_04_03_wPM1353_HS/wPM1353_HS_004.nd2",
         "/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/wPM1353_bet1_mSG/2025_04_03_wPM1353/2025_04_03_wPM1353_HS/n2v_denoise/denoised/wPM1353_HS_004_green_n2v.tif",
         "tailnuc"
        ],
        [
         "4",
         "wPM1353_HS_005",
         "2025-04-03",
         "bet1-mSG",
         "wPM1353",
         "HS",
         "5",
         "bet1-mSG_2025-04-03_wPM1353_HS_005",
         "/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/wPM1353_bet1_mSG/2025_04_03_wPM1353/2025_04_03_wPM1353_HS/wPM1353_HS_005.nd2",
         "/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/wPM1353_bet1_mSG/2025_04_03_wPM1353/2025_04_03_wPM1353_HS/n2v_denoise/denoised/wPM1353_HS_005_green_n2v.tif",
         "head"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>date</th>\n",
       "      <th>protein</th>\n",
       "      <th>strain</th>\n",
       "      <th>treatment</th>\n",
       "      <th>worm_id</th>\n",
       "      <th>id</th>\n",
       "      <th>raw_filepath</th>\n",
       "      <th>denoised_filepath</th>\n",
       "      <th>worm_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wPM1353_HS_001</td>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>bet1-mSG</td>\n",
       "      <td>wPM1353</td>\n",
       "      <td>HS</td>\n",
       "      <td>1</td>\n",
       "      <td>bet1-mSG_2025-04-03_wPM1353_HS_001</td>\n",
       "      <td>/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...</td>\n",
       "      <td>/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...</td>\n",
       "      <td>tailnuc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wPM1353_HS_002</td>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>bet1-mSG</td>\n",
       "      <td>wPM1353</td>\n",
       "      <td>HS</td>\n",
       "      <td>2</td>\n",
       "      <td>bet1-mSG_2025-04-03_wPM1353_HS_002</td>\n",
       "      <td>/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...</td>\n",
       "      <td>/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...</td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wPM1353_HS_003</td>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>bet1-mSG</td>\n",
       "      <td>wPM1353</td>\n",
       "      <td>HS</td>\n",
       "      <td>3</td>\n",
       "      <td>bet1-mSG_2025-04-03_wPM1353_HS_003</td>\n",
       "      <td>/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...</td>\n",
       "      <td>/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...</td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wPM1353_HS_004</td>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>bet1-mSG</td>\n",
       "      <td>wPM1353</td>\n",
       "      <td>HS</td>\n",
       "      <td>4</td>\n",
       "      <td>bet1-mSG_2025-04-03_wPM1353_HS_004</td>\n",
       "      <td>/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...</td>\n",
       "      <td>/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...</td>\n",
       "      <td>tailnuc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wPM1353_HS_005</td>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>bet1-mSG</td>\n",
       "      <td>wPM1353</td>\n",
       "      <td>HS</td>\n",
       "      <td>5</td>\n",
       "      <td>bet1-mSG_2025-04-03_wPM1353_HS_005</td>\n",
       "      <td>/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...</td>\n",
       "      <td>/mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...</td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename        date   protein   strain treatment  worm_id  \\\n",
       "0  wPM1353_HS_001  2025-04-03  bet1-mSG  wPM1353        HS        1   \n",
       "1  wPM1353_HS_002  2025-04-03  bet1-mSG  wPM1353        HS        2   \n",
       "2  wPM1353_HS_003  2025-04-03  bet1-mSG  wPM1353        HS        3   \n",
       "3  wPM1353_HS_004  2025-04-03  bet1-mSG  wPM1353        HS        4   \n",
       "4  wPM1353_HS_005  2025-04-03  bet1-mSG  wPM1353        HS        5   \n",
       "\n",
       "                                   id  \\\n",
       "0  bet1-mSG_2025-04-03_wPM1353_HS_001   \n",
       "1  bet1-mSG_2025-04-03_wPM1353_HS_002   \n",
       "2  bet1-mSG_2025-04-03_wPM1353_HS_003   \n",
       "3  bet1-mSG_2025-04-03_wPM1353_HS_004   \n",
       "4  bet1-mSG_2025-04-03_wPM1353_HS_005   \n",
       "\n",
       "                                        raw_filepath  \\\n",
       "0  /mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...   \n",
       "1  /mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...   \n",
       "2  /mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...   \n",
       "3  /mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...   \n",
       "4  /mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...   \n",
       "\n",
       "                                   denoised_filepath worm_region  \n",
       "0  /mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...     tailnuc  \n",
       "1  /mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...        head  \n",
       "2  /mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...        head  \n",
       "3  /mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...     tailnuc  \n",
       "4  /mnt/izbkingston/MeisterLab/Kalyan/TF_strains/...        head  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d6c4b",
   "metadata": {},
   "source": [
    "## Functions for nuclear segmentation and qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d68a0b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Disable do_3D, there is a bug. 2D and stitching with overlap works much better.\n",
    "# Takes around 7min for the whole image on the macbook\n",
    "def segment_nuclei(img, model):\n",
    "    ''' use pytorch cellpose model to segment nuclei'''\n",
    "    masks,flows,styles = model.eval(img,do_3D=False,stitch_threshold=0.3,cellprob_threshold =0,diameter =36)\n",
    "    return masks,flows,styles\n",
    "\n",
    "\n",
    "def calc_distance_mask(masks,anisotropy):\n",
    "    '''Calculate the distance map from the nuclei-edge towards the center of nucleus'''\n",
    "    masks_edt = edt.edt(masks,anisotropy = anisotropy)\n",
    "    return masks_edt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_qc_nuclei_crop(df, index, df_region_props, img, t=0, display = False, seed=1):\n",
    "    '''Plot a cropped region of a random sample of 10 nuclei from each image'''\n",
    "    nb_nuc = 10\n",
    "    np.random.seed(seed)\n",
    "    indices_to_sample = np.random.choice(range(len(df_region_props)),size = nb_nuc,replace = False)\n",
    "    # sort indeces in descending order of area\n",
    "\n",
    "    widths=[df_region_props['image'][i].shape[1] for i in indices_to_sample]\n",
    "\n",
    "    if spotChannel != nucChannel:\n",
    "        fig, axs = plt.subplots(nrows = 2, ncols = nb_nuc, figsize = (15,5),dpi = 250, \n",
    "                                sharex=False, sharey=False, width_ratios=widths)\n",
    "        \n",
    "        for i,sample in enumerate(indices_to_sample):\n",
    "            intensity_image = df_region_props['intensity_image'][sample][:,:,:,spotChannel] #show first spot channel\n",
    "            image = df_region_props['image'][sample]\n",
    "            mx = np.ma.masked_array(intensity_image,mask = ~image)\n",
    "            z_height = image.shape[0] \n",
    "            axs[0,i].imshow(mx[int(z_height/2)])\n",
    "            axs[0,i].spines['top'].set_visible(False)\n",
    "            axs[0,i].spines['right'].set_visible(False)\n",
    "            axs[0,i].spines['bottom'].set_visible(False)\n",
    "            axs[0,i].spines['left'].set_visible(False)\n",
    "            axs[0,i].get_xaxis().set_ticks([])\n",
    "            axs[0,i].get_yaxis().set_ticks([])\n",
    "        \n",
    "        for i,sample in enumerate(indices_to_sample):\n",
    "            intensity_image = df_region_props['intensity_image'][sample][:,:,:,nucChannel] #show second nuclear channel\n",
    "            image = df_region_props['image'][sample]\n",
    "            mx = np.ma.masked_array(intensity_image,mask = ~image)\n",
    "            z_height = image.shape[0]\n",
    "            axs[1,i].imshow(mx[int(z_height/2)])\n",
    "            axs[1,i].spines['top'].set_visible(False)\n",
    "            axs[1,i].spines['right'].set_visible(False)\n",
    "            axs[1,i].spines['bottom'].set_visible(False)\n",
    "            axs[1,i].spines['left'].set_visible(False)\n",
    "            axs[1,i].get_xaxis().set_ticks([])\n",
    "            axs[1,i].get_yaxis().set_ticks([])\n",
    "    else:\n",
    "        fig, axs = plt.subplots(nrows = 1, ncols = nb_nuc, figsize = (7.5,5),dpi = 250, \n",
    "                            sharex=False, sharey=False, width_ratios=widths)\n",
    "\n",
    "        for i,sample in enumerate(indices_to_sample):\n",
    "            intensity_image = df_region_props['intensity_image'][sample][:,:,:,spotChannel] #show first spot channel\n",
    "            image = df_region_props['image'][sample]\n",
    "            mx = np.ma.masked_array(intensity_image,mask = ~image)\n",
    "            z_height = image.shape[0] \n",
    "            axs[i].imshow(mx[int(z_height/2)])\n",
    "            axs[i].spines['top'].set_visible(False)\n",
    "            axs[i].spines['right'].set_visible(False)\n",
    "            axs[i].spines['bottom'].set_visible(False)\n",
    "            axs[i].spines['left'].set_visible(False)\n",
    "            axs[i].get_xaxis().set_ticks([])\n",
    "            axs[i].get_yaxis().set_ticks([])\n",
    "\n",
    "    fig.suptitle(f'Cropped nuclei {df.id.iloc[index]}', fontsize=16)\n",
    "\n",
    "    if i == nb_nuc-1:\n",
    "        scalebar = ScaleBar(0.065, \"um\", length_fraction=1, box_alpha=0.7,color='black',location='lower right',height_fraction = 0.05,border_pad =-1)\n",
    "        if spotChannel != nucChannel:\n",
    "            axs[1,i].add_artist(scalebar)\n",
    "        else:\n",
    "            axs[i].add_artist(scalebar)\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    fig.savefig(os.path.join(output_path,'qc/cropped_nuclei_'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.pdf'))\n",
    "    if display == False:\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_single_nucleus_crop(df, index, df_region_props, nuc_index, img):\n",
    "    '''Plot a cropped region of a particular nucleus'''\n",
    "    if spotChannel != nucChannel:\n",
    "        fig, axs = plt.subplots(nrows = 1, ncols = 2, figsize = (3,1.5),dpi = 250, sharey=True)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(nrows = 1, ncols = 1, figsize = (1.5,1.5),dpi = 250, sharey=True)\n",
    "    fig.suptitle(f'{df.id.iloc[index]}', fontsize=6)\n",
    "\n",
    "    intensity_image = df_region_props['intensity_image'][nuc_index][:,:,:,spotChannel] #show first spot channel\n",
    "    image = df_region_props['image'][nuc_index]\n",
    "    mx = np.ma.masked_array(intensity_image, mask = ~image)\n",
    "    z_height = image.shape[0] \n",
    "    axs[0].imshow(mx[int(z_height/2)])\n",
    "    axs[0].spines['top'].set_visible(False)\n",
    "    axs[0].spines['right'].set_visible(False)\n",
    "    axs[0].spines['bottom'].set_visible(False)\n",
    "    axs[0].spines['left'].set_visible(False)\n",
    "    axs[0].get_xaxis().set_ticks([])\n",
    "    axs[0].get_yaxis().set_ticks([])\n",
    "\n",
    "    if spotChannel != nucChannel:\n",
    "        intensity_image = df_region_props['intensity_image'][nuc_index][:,:,:,nucChannel] #show second nuclear channel\n",
    "        image = df_region_props['image'][nuc_index]\n",
    "        mx = np.ma.masked_array(intensity_image, mask = ~image)\n",
    "        z_height = image.shape[0]\n",
    "        axs[1].imshow(mx[int(z_height/2)])\n",
    "        axs[1].spines['top'].set_visible(False)\n",
    "        axs[1].spines['right'].set_visible(False)\n",
    "        axs[1].spines['bottom'].set_visible(False)\n",
    "        axs[1].spines['left'].set_visible(False)\n",
    "        axs[1].get_xaxis().set_ticks([])\n",
    "        axs[1].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "    scalebar = ScaleBar(0.065, \"um\", length_fraction=1, box_alpha=0.7,color='black',location='lower right',height_fraction = 0.05,border_pad =-1)\n",
    "    if spotChannel != nucChannel:\n",
    "        axs[1].add_artist(scalebar)\n",
    "    else:\n",
    "        axs[0].add_artist(scalebar) \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_qc_segmentation_xyz(img, masks, index, df, t=0, display_plot=False, plotContours=False):\n",
    "    '''Plot a 2x3 grid of xy, xz, yz slices of the image and the corresponding segmentation'''\n",
    "    nucChannel = 0\n",
    "    num_z=img.shape[1]\n",
    "    num_y=img.shape[2]\n",
    "    num_x=img.shape[3]\n",
    "    nlabel=100\n",
    "\n",
    "    fig = plt.figure(layout='constrained',dpi=450,figsize = (10,10))\n",
    "    fig.suptitle(f'Segmentation for {df.id.iloc[index]}', fontsize=10)\n",
    "    subfigs = fig.subfigures(2, 1, wspace=0.1)\n",
    "\n",
    "    axsTop = subfigs[0].subplots(2, 3,sharex=True, sharey=True)\n",
    "    #xy\n",
    "    axsTop[0,0].imshow(label2rgb(masks[int(num_z*0.3),:,:],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsTop[1,0].set_title('z='+str(int(num_z*0.3)), fontsize=8)\n",
    "    axsTop[0,1].imshow(label2rgb(masks[int(num_z*0.5),:,:],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsTop[1,1].set_title('z='+str(int(num_z*0.5)), fontsize=8)\n",
    "    axsTop[0,2].imshow(label2rgb(masks[int(num_z*0.7),:,:],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsTop[1,2].set_title('z='+str(int(num_z*0.7)), fontsize=8)\n",
    "\n",
    "    axsTop[1,0].imshow(img[nucChannel,int(num_z*0.3),:,:],cmap = 'gray_r')\n",
    "    axsTop[1,1].imshow(img[nucChannel,int(num_z*0.5),:,:],cmap = 'gray_r')\n",
    "    axsTop[1,2].imshow(img[nucChannel,int(num_z*0.7),:,:],cmap = 'gray_r')\n",
    "\n",
    "    if plotContours:\n",
    "        axsTop[1,0].contour(masks[int(num_z*0.3),:,:], [0.5], linewidths=0.5, colors='r')\n",
    "        axsTop[1,1].contour(masks[int(num_z*0.5),:,:], [0.5], linewidths=0.5, colors='r')\n",
    "        axsTop[1,2].contour(masks[int(num_z*0.7),:,:], [0.5], linewidths=0.5, colors='r')\n",
    "\n",
    "\n",
    "    for axss in axsTop:\n",
    "        for ax in axss:\n",
    "            #ax.set_xlim(0,num_x)\n",
    "            #ax.set_ylim(0,num_y)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    axsBottom = subfigs[1].subplots(4, 3,sharex=True,sharey=True)\n",
    "    #xz\n",
    "    axsBottom[0,0].imshow(label2rgb(masks[:,int(num_y*0.3),:],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsBottom[1,0].set_title('y='+str(int(num_y*0.3)), fontsize=8)\n",
    "    axsBottom[0,1].imshow(label2rgb(masks[:,int(num_y*0.5),:],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsBottom[1,1].set_title('y='+str(int(num_y*0.5)), fontsize=8)\n",
    "    axsBottom[0,2].imshow(label2rgb(masks[:,int(num_y*0.7),:],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsBottom[1,2].set_title('y='+str(int(num_y*0.7)), fontsize=8)\n",
    "\n",
    "    axsBottom[1,0].imshow(img[nucChannel,:,int(num_y*0.3),:],cmap = 'gray_r')\n",
    "    axsBottom[1,1].imshow(img[nucChannel,:,int(num_y*0.5),:],cmap = 'gray_r')\n",
    "    axsBottom[1,2].imshow(img[nucChannel,:,int(num_y*0.7),:],cmap = 'gray_r')\n",
    "\n",
    "    if plotContours:\n",
    "        axsBottom[1,0].contour(masks[:,int(num_y*0.3),:], [0.5], linewidths=0.5, colors='r')\n",
    "        axsBottom[1,1].contour(masks[:,int(num_y*0.5),:], [0.5], linewidths=0.5, colors='r')\n",
    "        axsBottom[1,2].contour(masks[:,int(num_y*0.7),:], [0.5], linewidths=0.5, colors='r')\n",
    "\n",
    "\n",
    "    #yz\n",
    "    axsBottom[2,0].imshow(label2rgb(masks[:,:,int(num_x*0.3)],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsBottom[3,0].set_title('x='+str(int(num_x*0.3)), fontsize=8)\n",
    "    axsBottom[2,1].imshow(label2rgb(masks[:,:,int(num_x*0.5)],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsBottom[3,1].set_title('x='+str(int(num_x*0.5)), fontsize=8)\n",
    "    axsBottom[2,2].imshow(label2rgb(masks[:,:,int(num_x*0.7)],bg_label=0,bg_color=(255, 255, 255),colors=np.random.random((nlabel, 3))))\n",
    "    axsBottom[3,2].set_title('x='+str(int(num_x*0.7)), fontsize=8)\n",
    "\n",
    "    axsBottom[3,0].imshow(img[nucChannel,:,:,int(num_x*0.3)],cmap = 'gray_r')\n",
    "    axsBottom[3,1].imshow(img[nucChannel,:,:,int(num_x*0.5)],cmap = 'gray_r')\n",
    "    axsBottom[3,2].imshow(img[nucChannel,:,:,int(num_x*0.7)],cmap = 'gray_r')\n",
    "\n",
    "    if plotContours:\n",
    "        axsBottom[3,0].contour(masks[:,:,int(num_x*0.3)], [0.5], linewidths=0.5, colors='r')\n",
    "        axsBottom[3,1].contour(masks[:,:,int(num_x*0.5)], [0.5], linewidths=0.5, colors='r')\n",
    "        axsBottom[3,2].contour(masks[:,:,int(num_x*0.7)], [0.5], linewidths=0.5, colors='r')\n",
    "\n",
    "    for axss in axsBottom:\n",
    "        for ax in axss:\n",
    "            #ax.set_ylim(0,num_z)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if display_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig.savefig(os.path.join(output_path,'qc','segmentation_'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2061263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the segmentation script on all images (reserve more than 24GB!)\n",
    "# this produces segmentation, segmentation_qc and edt files\n",
    "def run_nuclear_segmentation(indices, df, rerun=False, use_denoised=True):\n",
    "    '''Run the segmentation on all images in the dataframe'''\n",
    "    for index in tqdm.tqdm(indices):\n",
    "        if rerun or not os.path.exists(os.path.join(output_path,'edt',df.id.iloc[index]+'_t0.tif')):\n",
    "            # get anisotropy from raw image metadata\n",
    "            img_5d = BioImage(df.raw_filepath.iloc[index], reader=bioio_nd2.Reader)\n",
    "\n",
    "            ZvX = np.round(img_5d.physical_pixel_sizes.Z/img_5d.physical_pixel_sizes.X,0)\n",
    "            anisotropy = (ZvX,1,1)\n",
    "            # Load the denoised data\n",
    "            if use_denoised:\n",
    "                img_5d = BioImage(df.denoised_filepath.iloc[index], reader=bioio_tifffile.Reader)\n",
    "            for t in range(img_5d.dims.T):\n",
    "                img = img_5d.get_image_data(\"CZYX\", T=t)\n",
    "\n",
    "                # Segment nuclei \n",
    "                masks,flows,styles = segment_nuclei(img[nucChannel,:,:,:],model) # Run the segmentation\n",
    "                plot_qc_segmentation_xyz(img,masks,index, df, t, display_plot = False)                         # Create qc plot\n",
    "                OmeTiffWriter.save(masks, os.path.join(output_path,'segmentation',df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.tif'))\n",
    "\n",
    "                del flows\n",
    "                del styles\n",
    "                gc.collect()\n",
    "                \n",
    "                # Calculate edt \n",
    "                masks_edt = calc_distance_mask(masks,anisotropy)\n",
    "                OmeTiffWriter.save(masks_edt, os.path.join(output_path,'edt',df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.tif'))\n",
    "\n",
    "                del masks\n",
    "                del masks_edt\n",
    "                gc.collect()\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5ac28",
   "metadata": {},
   "source": [
    "## Functions for autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b95fad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nuc_background_image_mask(img, i, df_region_props, spotChannel):\n",
    "    '''\n",
    "    Uses bounding box for nucleus and the original image to extract\n",
    "    intensity values and mask for background pixels close to the nucleus.\n",
    "    '''\n",
    "    z1 = df_region_props['bbox-0'].iloc[i]\n",
    "    z2 = df_region_props['bbox-3'].iloc[i]\n",
    "    y1 = df_region_props['bbox-1'].iloc[i]\n",
    "    y2 = df_region_props['bbox-4'].iloc[i]\n",
    "    x1 = df_region_props['bbox-2'].iloc[i]\n",
    "    x2 = df_region_props['bbox-5'].iloc[i]\n",
    "    #print(z1,z2,y1,y2,x1,x2)\n",
    "    if z2==z1:\n",
    "        mskd = np.ma.masked_array(img[z1,y1:y2,x1:x2,spotChannel], mask = df_region_props['image'].iloc[i],fill_value=0)\n",
    "    else:\n",
    "        mskd = np.ma.masked_array(img[z1:z2,y1:y2,x1:x2,spotChannel], mask = df_region_props['image'].iloc[i],fill_value=0)\n",
    "    bg_image = mskd.data\n",
    "    bg_image[mskd.mask] = 0 # remove unwanted data to save space\n",
    "    # note that in masked arrays True is invalid data, so need to reverse logic of mask\n",
    "    bg_mask = np.logical_not(mskd.mask)\n",
    "    return(bg_image, bg_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "884b4cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_image_values(image,image_mask):\n",
    "    '''\n",
    "    Centers image values around the mean, taking\n",
    "    into account a mask, and zeros the masked region.\n",
    "    '''\n",
    "    norm_image=image-image[image_mask].mean()\n",
    "    norm_image[np.logical_not(image_mask)] = 0\n",
    "    return(norm_image)\n",
    "\n",
    "\n",
    "\n",
    "def get_autocorrelation_2d(img,img_mask,maxr=maxradius):\n",
    "    '''\n",
    "    Calculates autocorrelation function for a single\n",
    "    2-3d image with a mask, according to\n",
    "    Munschi et al. 2025, with additional normalisation\n",
    "    steps.\n",
    "    '''\n",
    "    xdim = img.shape[2]\n",
    "    ydim = img.shape[1]\n",
    "    zdim = img.shape[0]\n",
    "    norm_img = center_image_values(img,img_mask)\n",
    "    yautocorr = np.zeros((ydim))\n",
    "    xz_combinations=0\n",
    "    for x in range(0,xdim):\n",
    "        for z in range(0,zdim):\n",
    "            validPixels=np.sum(norm_img[z,:,x]!=0)\n",
    "            if validPixels>1:\n",
    "                result = np.correlate(norm_img[z,:,x],norm_img[z,:,x],mode='full')\n",
    "                yautocorr=yautocorr + result[result.size//2:]/(validPixels*(validPixels-1)/2)\n",
    "                xz_combinations+=1\n",
    "    if xz_combinations>0:\n",
    "        yautocorr = yautocorr/xz_combinations\n",
    "    else:\n",
    "        yautocorr = np.zeros((ydim))\n",
    "\n",
    "    \n",
    "    xautocorr = np.zeros((xdim))\n",
    "    yz_combinations=0\n",
    "    for y in range(0,ydim):\n",
    "        for z in range(0,zdim):\n",
    "            validPixels=np.sum(norm_img[z,y,:]!=0)\n",
    "            if validPixels>1:  \n",
    "                result = np.correlate(norm_img[z,y,:],norm_img[z,y,:],mode='full')\n",
    "                xautocorr=xautocorr + result[result.size//2:]/(validPixels*(validPixels-1)/2)\n",
    "                yz_combinations+=1\n",
    "    if yz_combinations>0:\n",
    "        xautocorr = xautocorr/yz_combinations\n",
    "    else:\n",
    "        xautocorr = np.zeros((xdim))\n",
    "    # pad the smaller autocorr to match the size of the larger one\n",
    "    if(xdim>=ydim):\n",
    "        yautocorr = np.pad(yautocorr,(0,xdim-ydim))\n",
    "    elif(ydim>xdim):\n",
    "        xautocorr = np.pad(xautocorr,(0,ydim-xdim))\n",
    "    # average the two autocorrs\n",
    "    autocorr = (xautocorr+yautocorr)/2\n",
    "    if(len(autocorr)<maxr): #ensure autocorr is long enough\n",
    "        autocorr = np.pad(autocorr,(0,maxr-len(autocorr)))\n",
    "    # normalise by total variance \n",
    "    varNorm = autocorr/np.var(norm_img[img_mask])\n",
    "    return(varNorm[1:maxr])\n",
    "\n",
    "\n",
    "def exponential_decay(x, a, b,c):\n",
    "    '''\n",
    "    Exponenetial decay function for autocorrelation\n",
    "    according to Munschi et al. 2025.\n",
    "    '''                           \n",
    "    return a + b * np.exp(-c * x)      \n",
    "\n",
    "\n",
    "def fit_acf(autocorr):\n",
    "    '''\n",
    "    Fits parameters of an exponential decay function \n",
    "    to the autocorrelation values. Used for single\n",
    "    nuclei.\n",
    "    '''\n",
    "    x=range(1,autocorr.size+1)\n",
    "    initialguess = [0.01, 0.01, 0.1]\n",
    "    autocorr = autocorr.astype(np.float64)\n",
    "    try:\n",
    "        fit, covariance = optimize.curve_fit(           \n",
    "            exponential_decay,                                     \n",
    "            x,   \n",
    "            autocorr,  #np.insert(autocorr,0,1),\n",
    "            initialguess,\n",
    "            bounds=([0 , 0, 0], [1., 1., 100]),\n",
    "            method='trf', \n",
    "            loss='linear')\n",
    "        if np.nan not in fit and np.all(np.isfinite(fit)):\n",
    "            rmse = np.sqrt(np.mean((autocorr - exponential_decay(x, *fit))**2))\n",
    "            conditionNumber = np.linalg.cond(covariance)\n",
    "        else:\n",
    "            rmse = np.nan \n",
    "            conditionNumber = np.nan\n",
    "    except RuntimeError:\n",
    "        fit = [0,0,0] #[np.nan, np.nan, np.nan]\n",
    "        covariance = np.zeros((3,3)) \n",
    "        rmse = np.nan \n",
    "        conditionNumber = np.nan\n",
    "    return(fit, covariance, rmse, conditionNumber)\n",
    "\n",
    "\n",
    "def correlation_length(fit):\n",
    "    '''\n",
    "    Calculates correlation length according to\n",
    "    Munschi et al. 2025.\n",
    "    '''\n",
    "    if np.nan not in fit:\n",
    "        c=fit[2]\n",
    "        x0=1\n",
    "        lam=x0+np.log(2)/c\n",
    "    else: \n",
    "        lam = 0 #np.nan\n",
    "    return(lam)\n",
    "\n",
    "\n",
    "def correlation_error(fit,cov):\n",
    "    '''\n",
    "    Calculates correlation length error according to\n",
    "    Munschi et al. 2025.\n",
    "    '''\n",
    "    if np.nan not in fit:\n",
    "        c=fit[2]\n",
    "        sigma_c = np.sqrt(cov[2,2])\n",
    "        lam = correlation_length(fit)\n",
    "        lam_error = lam*sigma_c/c\n",
    "    else:\n",
    "        lam_error = 0 #np.nan\n",
    "    return(lam_error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_autocorrelation_length(img,mask):\n",
    "    '''\n",
    "    Calculates autocorelation length from \n",
    "    a 2d or 3d image and mask. \n",
    "    '''\n",
    "    ac = get_autocorrelation_2d(img, mask, maxr=maxradius)\n",
    "    fit, cov, rmse, conditionNumber = fit_acf(ac)\n",
    "    fiterr = np.sqrt(np.diag(cov))\n",
    "    if np.nan not in fit:\n",
    "        ac_length = correlation_length(fit)\n",
    "        ac_error = correlation_error(fit, cov) \n",
    "        if(ac_length<np.abs(ac_error)):\n",
    "            ac_length = 0#np.nan\n",
    "            ac_error = 0#np.nan\n",
    "    else:\n",
    "        ac_length = 0#np.nan\n",
    "        ac_error = 0#np.nan\n",
    "    return(ac, ac_length, ac_error, rmse, conditionNumber, fit, fiterr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b0762eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for trouble shooting - plots ACF along with image of spot channel\n",
    "# when given the nuclei table along with an index number\n",
    "def plot_one_nucleus_acf(df, i):\n",
    "    '''\n",
    "    Plots the autocorrelation function for a specific row in the DataFrame\n",
    "    and displays the corresponding image in a second subplot.\n",
    "    '''\n",
    "    img = df['intensity_image'].iloc[i][:, :, :, spotChannel]\n",
    "    zdim=img.shape[0]\n",
    "    img_mask = df['image'].iloc[i]\n",
    "    autocorr = get_autocorrelation_2d(img, img_mask, maxr=maxradius)\n",
    "    fit, covariance, rmse, conditionNumber = fit_acf(autocorr)\n",
    "    fiterr = np.sqrt(np.diag(covariance))\n",
    "    x = range(1, autocorr.size + 1)\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "\n",
    "    # Plot the autocorrelation function in the first subplot\n",
    "    axes[0].plot(x, autocorr, 'o', label='data')\n",
    "    try:\n",
    "        axes[0].plot(x, exponential_decay(x, *fit), label='fit')\n",
    "    except:\n",
    "        pass\n",
    "    axes[0].legend()\n",
    "    axes[0].set_title('Autocorrelation '+str(i)+' '+df['quality'].iloc[i]+' '+df['confusion'].iloc[i])\n",
    "    axes[0].set_xlabel('Distance')\n",
    "    axes[0].set_ylabel('Autocorrelation')\n",
    "    axes[0].text(0.5, 0.5, \n",
    "                 f'lambda = {correlation_length(fit):.2f} +/- {correlation_error(fit, covariance):.2f}', \n",
    "                 transform=axes[0].transAxes)\n",
    "    axes[0].text(0.5, 0.6, 'fit: a={:.3g}±{:.3g},\\nb={:.3g}±{:.3g},\\nc={:.3g}±{:.3g}'.format(\n",
    "                     fit[0], fiterr[0], fit[1], fiterr[1], fit[2], fiterr[2]), \n",
    "                 transform=axes[0].transAxes)\n",
    "    axes[0].text(0.5, 0.7, 'RMSE = {:.3g}'.format(rmse), transform=axes[0].transAxes)\n",
    "    axes[0].text(0.5, 0.8, 'conditionNumber = {:.3g}'.format(conditionNumber), transform=axes[0].transAxes)\n",
    "    # Display the image in the second subplot\n",
    "    axes[1].imshow(img[int(zdim/2),:,:], cmap='gray')\n",
    "    axes[1].set_title('Spots Channel')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde787fe",
   "metadata": {},
   "source": [
    "## Function to extract nuclei measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ca1888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read images\n",
    "## crop the nuclei slices\n",
    "## calculate EDT transform\n",
    "## for each nuclei loop over all distances (1:40) and take mean\n",
    "## array of distance/intensity measurements are taken only for middle slice of mask (?)\n",
    "\n",
    "## nucleus_id | nucleus volume | [1:20] mean intensities | group | ...\n",
    "#indices=range(0,len(df))\n",
    "#run_dist_analysis(indices, df)\n",
    "\n",
    "def run_dist_analysis(indices,df, use_worm_masks = False):\n",
    "    '''Run the distance analysis on all images in the dataframe'''\n",
    "    for index in tqdm.tqdm(indices):\n",
    "        #print(df.iloc[index].raw_filepath)\n",
    "        img_5d = BioImage(df.raw_filepath.iloc[index], reader=bioio_nd2.Reader)\n",
    "        # calculate anisotropy from raw image metadata\n",
    "        ZvX = np.round(img_5d.physical_pixel_sizes.Z/img_5d.physical_pixel_sizes.X,0)\n",
    "        df_nuclei_all = pd.DataFrame()\n",
    "        for t in tqdm.tqdm(range(img_5d.dims.T)):\n",
    "            #print(t)\n",
    "            df_nuclei = pd.DataFrame()\n",
    "            img = img_5d.get_image_data(\"ZYXC\", T=t)\n",
    "\n",
    "            masks = BioImage(os.path.join(output_path,'segmentation',df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.tif'), reader=bioio_tifffile.Reader)\n",
    "            masks = masks.get_image_data(\"ZYX\", T=0, C=0)\n",
    "\n",
    "            # subset nuclear masks with masks of worm region\n",
    "            worm_mask_path = os.path.join(output_path, 'worm_masks', df.id.iloc[index] + '.tif')\n",
    "            if use_worm_masks and os.path.exists(worm_mask_path):\n",
    "                worm_mask = BioImage(worm_mask_path, reader=bioio_tifffile.Reader)\n",
    "                worm_mask = worm_mask.get_image_data(\"YX\",Z=0, T=0, C=0)\n",
    "                masks = masks * worm_mask\n",
    "\n",
    "            df_region_props = regionprops_table(masks,img, properties = ['label', 'bbox', 'area','centroid','MajorAxisLength','solidity','image','intensity_image'])\n",
    "            df_region_props = pd.DataFrame(df_region_props)\n",
    "\n",
    "            if len(df_region_props)>=10:\n",
    "                plot_qc_nuclei_crop(df, index, df_region_props, img, t=t, display = False) \n",
    "            \n",
    "            if len(df_region_props)>=1:\n",
    "                for i in tqdm.tqdm(range(len(df_region_props))):\n",
    "                    df_nuclei_temp = pd.DataFrame()\n",
    "\n",
    "                    intensity_image_spots = df_region_props['intensity_image'].iloc[i][:,:,:,spotChannel] #show spot channel\n",
    "                    if spotChannel != nucChannel:\n",
    "                        intensity_image_nuclei = df_region_props['intensity_image'].iloc[i][:,:,:,nucChannel] #show nuclear ring channel\n",
    "\n",
    "                    image = df_region_props['image'][i]  # binary 3d mask\n",
    "\n",
    "                    # Extract the intensity per distance\n",
    "                    mx_spots = np.ma.masked_array(intensity_image_spots, mask = ~image) # 3d masked spot channel\n",
    "                    if spotChannel != nucChannel:\n",
    "                        mx_nuclei = np.ma.masked_array(intensity_image_nuclei,mask = ~image) # 3d masked nuclear ring channel\n",
    "                    mx_mask = np.ma.masked_array(image,mask = ~image)  # 3d masked binary mask\n",
    "\n",
    "                    z_height = image.shape[0]\n",
    "\n",
    "                    slice_spots = mx_spots[int(z_height/2)]\n",
    "                    if spotChannel != nucChannel:\n",
    "                        slice_nuclei = mx_nuclei[int(z_height/2)]\n",
    "                    slice_mask = mx_mask[int(z_height/2)]\n",
    "\n",
    "                    slice_mask_edt = edt.edt(slice_mask)\n",
    "                    slice_mask_edt = np.ma.masked_array(slice_mask_edt, mask = ~(slice_mask_edt>0)) \n",
    "\n",
    "                    results = regionprops_table(slice_mask_edt.astype('int'),slice_spots,properties=['label','intensity_mean'])\n",
    "                    intensity_dist_spots = results['intensity_mean']\n",
    "\n",
    "                    if spotChannel != nucChannel:\n",
    "                        results = regionprops_table(slice_mask_edt.astype('int'),slice_nuclei,properties=['label','intensity_mean'])\n",
    "                        intensity_dist_nuclei = results['intensity_mean']\n",
    "\n",
    "                    dist = results['label']\n",
    "\n",
    "                    #background pixels for from bounding box of nucleus\n",
    "                    bg_image, bg_mask = get_nuc_background_image_mask(img, i, df_region_props, spotChannel)\n",
    "\n",
    "                    df_nuclei_temp =  pd.DataFrame([df_region_props.iloc[i]])\n",
    "                    df_nuclei_temp.rename(columns = {\"centroid-0\": \"centroid_z\", \"centroid-1\": \"centroid_y\", \"centroid-2\": \"centroid_x\",\n",
    "                                                    \"MajorAxisLength\": \"major_axis_length\"}, inplace = True)\n",
    "                    df_nuclei_temp['intensity_background'] = [bg_image]\n",
    "                    df_nuclei_temp['mask_background'] = [bg_mask]\n",
    "                    df_nuclei_temp['bb_dimZ']  = [mx_spots.shape[0]]\n",
    "                    df_nuclei_temp['bb_dimY']  = [mx_spots.shape[1]]\n",
    "                    df_nuclei_temp['bb_dimX']  = [mx_spots.shape[2]]\n",
    "                    df_nuclei_temp['mean'] = np.ma.mean(mx_spots)\n",
    "                    df_nuclei_temp['median'] = np.ma.median(mx_spots)\n",
    "                    df_nuclei_temp['std']=  np.ma.std(mx_spots)\n",
    "                    df_nuclei_temp['sum']= np.ma.sum(mx_spots)\n",
    "                    df_nuclei_temp['variance']= np.ma.var(mx_spots)\n",
    "                    df_nuclei_temp['max'] = np.ma.max(mx_spots)\n",
    "                    df_nuclei_temp['min'] = np.ma.min(mx_spots)\n",
    "                    df_nuclei_temp['volume'] = np.sum(np.invert(mx_spots.mask))\n",
    "                    df_nuclei_temp['mean_background'] = bg_image[bg_mask].mean()\n",
    "                    df_nuclei_temp['std_background'] = bg_image[bg_mask].std()\n",
    "                    df_nuclei_temp['sum_background'] = bg_image[bg_mask].sum()\n",
    "                    df_nuclei_temp['volume_background'] = bg_mask.sum()\n",
    "                    df_nuclei_temp['id'] = df.id.iloc[index]\n",
    "                    df_nuclei_temp['timepoint'] = t\n",
    "                    df_nuclei_temp['intensity_dist_spots'] = [intensity_dist_spots] # this is the spot channel but not actual detected spots\n",
    "                    if spotChannel != nucChannel:\n",
    "                        df_nuclei_temp['intensity_dist_nuclei'] = [intensity_dist_nuclei]  # this is the emerin ring channel intensity on central slice\n",
    "                    df_nuclei_temp['intensity_dist'] = [dist]  # this is the distance from the edge of the nucleus\n",
    "                    df_nuclei_temp['zproj_spots'] = [np.max(intensity_image_spots[:,:,:], axis = 0)]\n",
    "                    if spotChannel != nucChannel:\n",
    "                        df_nuclei_temp['zproj_nuclei'] = [np.max(intensity_image_nuclei[:,:,:], axis = 0)]\n",
    "                    df_nuclei_temp['zproj_background'] = [np.max(bg_image[:,:,:], axis = 0)]\n",
    "                    df_nuclei_temp['anisotropy'] = ZvX\n",
    "                    df_nuclei_temp['pixelSize'] = img_5d.physical_pixel_sizes.X\n",
    "\n",
    "                    # get autocorrelation data\n",
    "                    ac, ac_length, ac_error, rmse, conditionNumber, fit, fiterr = get_autocorrelation_length(df_nuclei_temp['intensity_image'].iloc[0][:,:,:,spotChannel],df_nuclei_temp['image'].iloc[0])\n",
    "                    df_nuclei_temp['spot_ACF'] = [ac]\n",
    "                    df_nuclei_temp['spot_ac_length'] = ac_length\n",
    "                    df_nuclei_temp['spot_ac_error'] = ac_error\n",
    "                    df_nuclei_temp['spot_ac_rmse'] = rmse\n",
    "                    df_nuclei_temp['spot_ac_conditionNumber'] = conditionNumber\n",
    "                    df_nuclei_temp['spot_ac_fittedParams'] = [fit]\n",
    "                    df_nuclei_temp['spot_ac_fittedParams_err'] = [fiterr]\n",
    "\n",
    "                    if spotChannel != nucChannel:\n",
    "                        ac, ac_length, ac_error, rmse, conditionNumber, fit, fiterr = get_autocorrelation_length(df_nuclei_temp['intensity_image'].iloc[0][:,:,:,nucChannel],df_nuclei_temp['image'].iloc[0])\n",
    "                        df_nuclei_temp['nuc_ACF'] = [ac]\n",
    "                        df_nuclei_temp['nuc_ac_length'] = ac_length\n",
    "                        df_nuclei_temp['nuc_ac_error'] = ac_error\n",
    "                        df_nuclei_temp['nuc_ac_rmse'] = rmse\n",
    "                        df_nuclei_temp['nuc_ac_conditionNumber'] = conditionNumber\n",
    "                        df_nuclei_temp['nuc_ac_fittedParams'] = [fit]\n",
    "                        df_nuclei_temp['nuc_ac_fittedParams_err'] = [fiterr]\n",
    "\n",
    "                    ac, ac_length, ac_error, rmse, conditionNumber, fit, fiterr = get_autocorrelation_length(df_nuclei_temp['intensity_background'].iloc[0],df_nuclei_temp['mask_background'].iloc[0])\n",
    "                    df_nuclei_temp['bg_ACF'] = [ac]\n",
    "                    df_nuclei_temp['bg_ac_length'] = ac_length\n",
    "                    df_nuclei_temp['bg_ac_error'] =  ac_error\n",
    "                    df_nuclei_temp['bg_ac_rmse'] = rmse\n",
    "                    df_nuclei_temp['bg_ac_conditionNumber'] = conditionNumber\n",
    "                    df_nuclei_temp['bg_ac_fittedParams'] = [fit]\n",
    "                    df_nuclei_temp['bg_ac_fittedParams_err'] = [fiterr]\n",
    "\n",
    "                    df_nuclei = pd.concat([df_nuclei,df_nuclei_temp])\n",
    "\n",
    "                df_nuclei_all = pd.concat([df_nuclei_all,df_nuclei])\n",
    "\n",
    "        if(len(df_nuclei_all) > 0):\n",
    "            # merge with metadata\n",
    "            df_for_csv = df.merge(df_nuclei_all,on='id',how='right')\n",
    "            # save as pickle because has array stored in Dataframe\n",
    "            df_for_csv.reset_index(drop=True, inplace=True)\n",
    "            df_for_csv.to_pickle(os.path.join(output_path,'dist',df.id.iloc[index]+'.pkl')) # Back up the DF for this FOV\n",
    "\n",
    "            # save simple data as table \n",
    "            simple_columns = [col for col in df_for_csv.columns if df_for_csv[col].apply(lambda x: not isinstance(x, (list, np.ndarray))).all()]\n",
    "            df_for_csv[simple_columns].to_csv(os.path.join(output_path,'nuclei',df.id.iloc[index]+'.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5596bfee",
   "metadata": {},
   "source": [
    "## Functions for spot detection and qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b7b6731-732e-453e-b8a4-7b1e1fb43ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_spots(img, diameter=(9,5,5), separation=(3,2,2)):\n",
    "    '''Find protein clusters of a certain size. Method is very sensitive, be sure to filter the spots afterwards using the signal value.\n",
    "    Input: img -> 3D array from C0 containing\n",
    "    Output: pandas.df containing data with all the detected spots.\n",
    "            x,y,z: centroid of spot in image coordinates (px space)\n",
    "            mass: total integrated brightness of the blob\n",
    "            size: radius of gyration of its Gaussian-like profile\n",
    "            ecc: eccentricity\n",
    "            raw_mass: integrated brightness in raw_image '''\n",
    "\n",
    "    #features = tp.locate(img, diameter=diameter, engine='numba',minmass = 10,percentile = 0.95,max_iterations=3,preprocess = True) #check \n",
    "    features = tp.locate(img[:,:,:], diameter, minmass=None, maxsize=None, separation=separation, noise_size=1, smoothing_size=None, threshold=None, invert=False, percentile=95, topn=None, preprocess=True, max_iterations=3, filter_before=None, filter_after=None, characterize=True, engine='numba')\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_spot_features(features, masks, masks_edt):\n",
    "    '''For each spot get the label of the corresponding nucleus and distance to its envelope.'''\n",
    "\n",
    "    for feature in features.iterrows():\n",
    "        index = feature[0]\n",
    "        x = round(feature[1].x)\n",
    "        y = round(feature[1].y)\n",
    "        z = round(feature[1].z)\n",
    "        dist = masks_edt[z,y,x]\n",
    "        label = masks[z,y,x]\n",
    "        features.loc[index,'dist'] = dist\n",
    "        features.loc[index,'label'] = int(label)\n",
    "        \n",
    "    return features\n",
    "#features = extract_spot_features(features,masks,masks_edt)\n",
    "\n",
    "def filter_spots(features, measure = 'signal', signal_strength = 0.1):\n",
    "    '''Remove all spots that lie outside of a nucleus (or where nucleus is not detected.\n",
    "       Remove all spots with signal<signal_strength'''\n",
    "    features_filt = features[(features['dist']>0)&(features[measure]>signal_strength)]\n",
    "    return features_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f546a5be-5c00-4cdd-83ec-8133d19cf190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_qc_spot_detection(index, df, df_features, img, t=0, display_plot = False,\n",
    "                            measure = 'signal', thresholds = [1 ,2.5, 5, 10]):\n",
    "    '''Plot the spot detection for a given image using several thresholds for the signal strength (shown on Z projections)'''\n",
    "    z_projection = np.max(img[:,:,:], axis = 0)\n",
    "    #masks_z_projection = np.max(masks[:,:,:], axis = 0)\n",
    "    features_filt_01 = filter_spots(df_features, measure = measure, signal_strength = thresholds[0])\n",
    "    features_filt_02 = filter_spots(df_features, measure = measure, signal_strength = thresholds[1])\n",
    "    features_filt_03 = filter_spots(df_features, measure = measure, signal_strength =  thresholds[2])\n",
    "    features_filt_04 = filter_spots(df_features, measure = measure, signal_strength = thresholds[3])\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(2,2,figsize = (6,7),dpi= 450)\n",
    "\n",
    "    for axss in axs:\n",
    "        for ax in axss:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "\n",
    "    axs[0,0].imshow(z_projection, cmap = 'gray_r')\n",
    "    axs[0,0].scatter(features_filt_01[['x']],features_filt_01[['y']], s = 0.3, linewidths=0.1, alpha = 1, edgecolors = 'red', facecolors='none')\n",
    "    #axs[0,0].contour(masks_z_projection, [0.5], linewidths=0.5, colors='green')\n",
    "    axs[0,0].set_title(f'{measure}>{thresholds[0]} (n={len(features_filt_01)})', fontsize=8,y=-0.01)\n",
    "\n",
    "    axs[0,1].imshow(z_projection, cmap = 'gray_r')\n",
    "    axs[0,1].scatter(features_filt_02[['x']],features_filt_02[['y']], s = 0.3, linewidths=0.1, alpha = 1, edgecolors = 'red', facecolors='none')\n",
    "    #axs[0,1].contour(masks_z_projection, [0.5], linewidths=0.5, colors='green')\n",
    "    axs[0,1].set_title(f'{measure}>{thresholds[1]} (n={len(features_filt_02)})', fontsize=8,y=-0.01)\n",
    "\n",
    "    axs[1,0].imshow(z_projection, cmap = 'gray_r')\n",
    "    axs[1,0].scatter(features_filt_03[['x']],features_filt_03[['y']], s = 0.3, linewidths=0.11, alpha = 1, edgecolors = 'red', facecolors='none')\n",
    "    #axs[1,0].contour(masks_z_projection, [0.5], linewidths=0.5, colors='green')\n",
    "    axs[1,0].set_title(f'{measure}>{thresholds[2]} (n={len(features_filt_03)})', fontsize=8,y=-0.01)\n",
    "\n",
    "    axs[1,1].imshow(z_projection, cmap = 'gray_r')\n",
    "    axs[1,1].scatter(features_filt_04[['x']],features_filt_04[['y']], s = 0.3, linewidths=0.1, alpha = 1, edgecolors = 'red', facecolors='none')\n",
    "    #axs[1,1].contour(masks_z_projection, [0.5], linewidths=0.5, colors='green')\n",
    "    axs[1,1].set_title(f'{measure}>{thresholds[3]} (n={len(features_filt_04)})', fontsize=8,y=-0.01)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle(f'Spot detection for {df.filename.iloc[index]}', fontsize=10)\n",
    "    #xs[0,0].imshow(masks[10,:,:]>0,cmap = 'gray_r')\n",
    "\n",
    "    if display_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig.savefig(os.path.join(output_path,'qc','spots_'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.png'))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e58611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_qc_spot_threshold(index, df, df_spots, t=0, display_plot=False, measure='signal'):\n",
    "    ''' Fits mixed gaussian model to find threshold of spot mass\n",
    "\n",
    "    Parameters:\n",
    "    index (int): Index of image whose spots should be analysed\n",
    "    df (pd.DataFrame): Data frame with list of image ids\n",
    "\n",
    "    Returns:\n",
    "    Saves a spotThreshold__.pdf for each image with a histogram, model fit and \n",
    "    threshold and returns image id, number of spots and the estimated threshold\n",
    "    '''\n",
    "    #df_spots = pd.read_csv(output_path+'spots/'+df.id.iloc[index]+'.csv')\n",
    "    #df_spots = df_spots[df_spots['timepoint']==t]\n",
    "    x = np.array(df_spots[measure]).reshape(-1,1)\n",
    "    gm =GaussianMixture(n_components=2,random_state=0).fit(x)\n",
    "    mu1=gm.means_[0]\n",
    "    mu2=gm.means_[1]\n",
    "    sigma1=np.sqrt(gm.covariances_[0])\n",
    "    sigma2=np.sqrt(gm.covariances_[1])\n",
    "    threshold=np.round(float(mu1+3*sigma1),2)\n",
    "\n",
    "    x_fit = np.linspace(0,max(x),100)\n",
    "    y_fit = gm.score_samples(x_fit)\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    g = sns.histplot(data=df_spots,x=measure,stat='density',label=\"Data\")\n",
    "    plt.plot(x_fit,np.exp(y_fit),color='red',lw=1,ls='-',label=\"Fitted bimodal distribution\")\n",
    "    plt.axvline(mu1,0,1,color='red',lw=0.5,ls=\"--\",label=\"Mean first gaussian\")\n",
    "    plt.axvline(threshold,0,1,color='red',lw=2,ls=\"-\",label=\"Threshold (mean1+3*SD1)\")\n",
    "    plt.axvline(mu2,0,1,color='red',lw=0.5,ls=\":\",label=\"Mean second gaussian\")\n",
    "    plt.annotate('Threshold='+str(threshold),xy=(0.4,0.9),xycoords='axes fraction')\n",
    "    plt.title('Distribution of spot '+measure+' as mixture of two gaussians')\n",
    "    plt.xlabel(measure)\n",
    "    plt.legend()\n",
    "\n",
    "    if display_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(os.path.join(output_path ,'qc','spotGMM_'+df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.pdf'))\n",
    "        plt.close()\n",
    "    id=df.id.iloc[index]\n",
    "    num_spot=len(df_spots)\n",
    "    return(num_spot, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b103e2-a6fa-47cb-8323-cc1dcdc4a59a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_spot_analysis(indices, df, useRaw=True, diameter=(7,9,9), separation=(5,7,7), qc_thresholds=[1,2.5,5,10]):\n",
    "    '''Finds spots and estimates threshold'''\n",
    "    ids = list()\n",
    "    num_spots = list()\n",
    "    thresholds = list()\n",
    "    timepoints = list()\n",
    "    for index in tqdm.tqdm(indices):\n",
    "        # Load the data\n",
    "        # with ND2Reader(df.filepath.iloc[index]) as images:\n",
    "        #     images.bundle_axes = ['z','x','y','c']\n",
    "        #     img = images[0]\n",
    "        df_features = pd.DataFrame()\n",
    "        if useRaw:\n",
    "            img_5d = BioImage(df.raw_filepath.iloc[index], reader=bioio_nd2.Reader)\n",
    "        else:\n",
    "            img_5d = BioImage(df.denoised_filepath.iloc[index], reader=bioio_tifffile.Reader)\n",
    "        \n",
    "        for t in range(img_5d.dims.T):\n",
    "            img = img_5d.get_image_data(\"ZYX\", T=t, C=spotChannel)\n",
    "\n",
    "            # get masks for this timepoint\n",
    "            masks = BioImage(os.path.join(output_path,'segmentation',df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.tif'), reader=bioio_tifffile.Reader)\n",
    "            masks = masks.get_image_data(\"ZYX\", T=0, C=0)\n",
    "\n",
    "            masks_edt = BioImage(os.path.join(output_path,'edt',df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.tif'), reader=bioio_tifffile.Reader)\n",
    "            masks_edt = masks_edt.get_image_data(\"ZYX\", T=0, C=0)\n",
    "\n",
    "            # Find the spots (location given in image coordinate system )\n",
    "            df_spots = find_spots(img[:,:,:],diameter = diameter,separation = separation)\n",
    "            df_features_temp = extract_spot_features(df_spots, masks, masks_edt)    # For all the spots calculate the features\n",
    "\n",
    "            \n",
    "            df_features_temp = filter_spots(df_features_temp, measure='signal', signal_strength = 0.0001)\n",
    "            if len(df_features_temp) == 0:\n",
    "                print('EMPTY DF!!')\n",
    "                print(df.filename.iloc[index])\n",
    "                print('INDEX:' + str(index))\n",
    "            else:\n",
    "                print('found spots:' + str(len(df_features_temp)))\n",
    "\n",
    "\n",
    "            df_features_temp.loc[:,'id'] = df.id.iloc[index]\n",
    "            df_features_temp.loc[:,'timepoint'] = t\n",
    "\n",
    "            #plot spots detected at different thresholds\n",
    "            plot_qc_spot_detection(index, df, df_features_temp, img, t=t, display_plot = False, measure = 'signal', thresholds = qc_thresholds) # Plot and save the QC of the spot detection\n",
    "\n",
    "            # Use mixed Guassian model to separate background from true spots\n",
    "            num_spot, threshold = plot_qc_spot_threshold(index, df, df_features_temp, t=t, display_plot = False, measure = 'signal')\n",
    "            ids.append(df.id.iloc[index])\n",
    "            timepoints.append(t)\n",
    "            num_spots.append(num_spot)\n",
    "            thresholds.append(threshold)\n",
    "\n",
    "            # append to main table\n",
    "            df_features = pd.concat([df_features,df_features_temp])\n",
    "\n",
    "        # output spot table for each raw image\n",
    "        df_features.to_csv(os.path.join(output_path,'spots',df.id.iloc[index]+'.csv')) # Back up the DF for this FOV\n",
    "\n",
    "    # output table of spot numbers and thresholds for all images\n",
    "    df_thresholds = pd.DataFrame(data = {'id': ids, 'timepoint': timepoints, 'num_spots': num_spots, 'threshold': thresholds })\n",
    "    df_thresholds.to_csv(os.path.join(output_path,'spotGMMthresholds.csv'),index=False)\n",
    "    return df_thresholds\n",
    "\n",
    "\n",
    "def replot_spots_with_thresholds(indices, df, useRaw=True, qc_thresholds=[1,2.5,5,10]):\n",
    "    '''Replots the spot qc images without recalculating the spots, so one can try different qc thresholds'''\n",
    "    for index in tqdm.tqdm(indices):\n",
    "        # Load the data\n",
    "        # with ND2Reader(df.filepath.iloc[index]) as images:\n",
    "        #     images.bundle_axes = ['z','x','y','c']\n",
    "        #     img = images[0]\n",
    "        if useRaw:\n",
    "            img_5d = BioImage(df.raw_filepath.iloc[index], reader=bioio_nd2.Reader)\n",
    "        else:\n",
    "            img_5d = BioImage(df.denoised_filepath.iloc[index], reader=bioio_tifffile.Reader)\n",
    "        \n",
    "        df_features =  pd.read_csv(os.path.join(output_path,'spots',df.id.iloc[index]+'.csv')) # get spots data\n",
    "\n",
    "        for t in range(img_5d.dims.T):\n",
    "            img = img_5d.get_image_data(\"ZYX\", T=t, C=spotChannel)\n",
    "\n",
    "            # Get masks\n",
    "            masks = BioImage(os.path.join(output_path,'segmentation',df.id.iloc[index]+'_t'+'{:02d}'.format(t)+'.tif'), reader=bioio_tifffile.Reader)\n",
    "            masks = masks.get_image_data(\"ZYX\", T=0, C=0)\n",
    "\n",
    "            df_features_temp = df_features[df_features['timepoint'] == t]\n",
    "            \n",
    "            #plot spots detected at different thresholds\n",
    "            plot_qc_spot_detection(index, df, df_features_temp, img, t=t, display_plot = False, measure = 'signal', thresholds = qc_thresholds) # Plot and save the QC of the spot detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b657443",
   "metadata": {},
   "source": [
    "## Functions to gather results into single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_nuclear_segmentation_data(indices, df, suffix = 'v001'):\n",
    "    '''Collects nuclear intensity and intensity vs distance data for all nuclei in the dataset'''\n",
    "    df_nuclei = pd.DataFrame()\n",
    "    for index in tqdm.tqdm(indices):\n",
    "        if os.path.exists(os.path.join(output_path,'nuclei',df.id.iloc[index]+'.csv')):\n",
    "            df_tmp = pd.read_csv(os.path.join(output_path,'nuclei',df.id.iloc[index]+'.csv'))\n",
    "            df_nuclei = pd.concat([df_nuclei,df_tmp])\n",
    "    df_nuclei.to_csv(os.path.join(output_path,'nuclei_analysis_'+suffix+'.csv'),index=False)\n",
    "\n",
    "\n",
    "\n",
    "def collect_nuclear_distance_data(indices, df, suffix = 'v001'):\n",
    "    '''Collects nuclear intensity and intensity vs distance data for all nuclei in the dataset'''\n",
    "    df_dist = pd.DataFrame()\n",
    "    for index in tqdm.tqdm(indices):\n",
    "        if os.path.exists(os.path.join(output_path,'dist',df.id.iloc[index]+'.pkl')):\n",
    "            df_tmp = pd.read_pickle(os.path.join(output_path,'dist',df.id.iloc[index]+'.pkl'))\n",
    "            df_dist = pd.concat([df_dist,df_tmp])\n",
    "    df_dist.to_pickle(os.path.join(output_path,'dist_analysis_'+suffix+'.pkl'))\n",
    "\n",
    "\n",
    "def collect_spot_data(indices, df, suffix = 'v001'):\n",
    "    '''Collects spot data for all images'''\n",
    "    df_spots = pd.DataFrame()\n",
    "    for index in tqdm.tqdm(indices):\n",
    "        if os.path.exists(os.path.join(output_path,'spots',df.id.iloc[index]+'.csv')):\n",
    "            df_tmp = pd.read_csv(os.path.join(output_path,'spots',df.id.iloc[index]+'.csv'))\n",
    "            df_spots = pd.concat([df_spots,df_tmp])\n",
    "    df_spots.to_csv(os.path.join(output_path,'spots_analysis_'+suffix+'.csv'),index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5278b",
   "metadata": {},
   "source": [
    "## Running the analysis for nuclear segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run analysis to segment nuclei\n",
    "indices=range(0,len(df))\n",
    "#23\n",
    "#indices=range(23,24)\n",
    "\n",
    "#run_nuclear_segmentation(indices, df, rerun=True, use_denoised=False) \n",
    "\n",
    "run_dist_analysis(indices, df, use_worm_masks = True)\n",
    "\n",
    "#collect_nuclear_segmentation_data(indices, df, suffix = 'v002')\n",
    "#collect_nuclear_distance_data(indices, df, suffix = 'v002')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a487a",
   "metadata": {},
   "source": [
    "## Running the analysis for spot detection\n",
    "This is currently not working well so can ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ed966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices=[0]\n",
    "indices=range(0,len(df))\n",
    "\n",
    "run_spot_analysis(indices, df, useRaw=True, diameter=(7,9,9), separation=(7,9,9), qc_thresholds=[1,3,6,10])\n",
    "#replot_spots_with_thresholds(indices, df, useRaw=False, qc_thresholds=[10, 15, 20, 25])\n",
    "\n",
    "collect_spot_data(indices, df, suffix = 'v001')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhcellpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
